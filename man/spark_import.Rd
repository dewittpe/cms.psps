% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/spark_import.R
\name{spark_import}
\alias{spark_import}
\alias{spark_psps_import_2010}
\title{Spark Import Functions for the PSPS data}
\usage{
spark_psps_import_2010(sc, path = NULL, envir = .GlobalEnv, ...)
}
\arguments{
\item{sc}{a sparklyr cluster}

\item{path}{path to the directory where the downloaded data is stored.}

\item{envir}{the envir to assign the \code{tbl_spark} object too, defatuls to
the global environment.}

\item{...}{arguments passed to \code{\link[sparklyr]{spark_read_csv}} (for
the import of 2017 data) or to \code{\link[sparklyr]{spark_read_text}} for
the years 2004 through 2016.}
}
\value{
A \code{tbl_spark} object of the name psps_<year> will be in the
\code{envir}.
}
\description{
Importing the PSPS data into spark via sparklyr
}
\examples{
\donttest{

sc <- sparklyr::spark_connect("local")

ls()
spark_psps_import_2010(sc, memory = FALSE)
psps_2010

#spark_psps_import_2011(sc, memory = FALSE)
#spark_psps_import_2012(sc, memory = FALSE)
#spark_psps_import_2013(sc, memory = FALSE)
#spark_psps_import_2014(sc, memory = FALSE)
#spark_psps_import_2015(sc, memory = FALSE)
#spark_psps_import_2016(sc, memory = FALSE)
#spark_psps_import_2017(sc, memory = FALSE)
#spark_psps_import_2018(sc, memory = FALSE)

ls()

sparklyr::spark_disconnect(sc)

}


}
